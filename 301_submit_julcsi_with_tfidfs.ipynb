{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import seaborn as sns\n",
    "import statsmodels as sm\n",
    "from pylab import rcParams\n",
    "from pylab import *\n",
    "from matplotlib.dates import date2num , DateFormatter\n",
    "from PIL import Image\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(font_scale=1.0)\n",
    "rcParams['figure.figsize'] = 8, 6\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette(sns.color_palette('muted'))\n",
    "\n",
    "pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = pd.concat([pd.read_csv('tmp/train_ids.csv', index_col='id'),\n",
    "               pd.read_csv('tmp/test_ids.csv', index_col='id')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_bathrooms.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_bedrooms.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_building_id.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_created.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_description.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_display_address.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_features.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_latlon.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_manager_id.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_photos.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_price.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_street_address.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low       34284\n",
       "medium    11229\n",
       "high       3839\n",
       "Name: interest_level, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.interest_level.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124011 entries, 0 to 124010\n",
      "Columns: 103 entries, listing_id to daddr_saddr_same\n",
      "dtypes: float64(49), int64(42), object(12)\n",
      "memory usage: 98.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# d = pd.concat([d, tf_idfs], axis=1)\n",
    "d.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49352\n"
     ]
    }
   ],
   "source": [
    "tr = d[d.interest_level.notnull()].copy()\n",
    "print len(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trl = tr.interest_level.copy()\n",
    "trf = tr\n",
    "del trf['interest_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74659\n"
     ]
    }
   ],
   "source": [
    "te = d[d.interest_level.isnull()].copy()\n",
    "print len(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tef = te\n",
    "del tef['interest_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical = [\"manager_id\", \"building_id\"]\n",
    "for f in categorical:\n",
    "        if trf[f].dtype=='object':\n",
    "            #print(f)\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(trf[f].values) + list(tef[f].values))\n",
    "            trf[f] = lbl.transform(list(trf[f].values))\n",
    "            tef[f] = lbl.transform(list(tef[f].values))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'listing_id', u'bathrooms', u'num_bathrooms_bucket', u'bedrooms',\n",
       "       u'num_bedrooms_bucket', u'building_id', u'num_apts_in_building',\n",
       "       u'num_apts_in_building_q10', u'created', u'created_utc',\n",
       "       ...\n",
       "       u'price_q10_all', u'price_q100_all', u'price_q10', u'price_q100',\n",
       "       u'street_address', u'saddr_num_words', u'saddr_has_number',\n",
       "       u'saddr_has_ordinal', u'saddr_num_upper_words', u'daddr_saddr_same'],\n",
       "      dtype='object', length=102)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tfidf_features = CountVectorizer(stop_words='english', max_features=400)\n",
    "tr_sparse_features = tfidf.fit_transform(trf[\"features\"])\n",
    "te_sparse_features = tfidf.transform(tef[\"features\"])\n",
    "\n",
    "tfidf_desc = CountVectorizer(stop_words='english', max_features=400)\n",
    "tr_sparse_desc = tfidf.fit_transform(trf[\"desc_clean\"].fillna(\"\"))\n",
    "te_sparse_desc = tfidf.transform(tef[\"desc_clean\"].fillna(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in trf.columns:\n",
    "    if trf.dtypes[c] not in ('int64', 'float64'):\n",
    "        del trf[c]           \n",
    "            \n",
    "for c in tef.columns:\n",
    "    if tef.dtypes[c] not in ('int64', 'float64'):\n",
    "        del tef[c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=1000):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 4\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.8\n",
    "    param['colsample_bytree'] = 0.8\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = sparse.hstack([trf,tr_sparse_features, tr_sparse_desc]).tocsr()\n",
    "test_X = sparse.hstack([tef,te_sparse_features, te_sparse_desc]).tocsr()\n",
    "\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "train_y = np.array(trl.apply(lambda x: target_num_map[x]))\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds, model = runXGB(train_X, train_y, test_X, num_rounds=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = pd.read_csv('input/sample_submission.csv').listing_id.values\n",
    "out_df.to_csv(\"output/xgb_starter_3_own_features_tfidf_desc_manager_building.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cvXGB(train_X, train_y, test_X, seed_val=0, num_rounds=1000):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 4\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.8\n",
    "    param['colsample_bytree'] = 0.8\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    eval_hist = xgb.cv(plst, xgtrain, num_rounds, nfold=3)\n",
    "\n",
    "    \n",
    "    return eval_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-mlogloss-mean</th>\n",
       "      <th>test-mlogloss-std</th>\n",
       "      <th>train-mlogloss-mean</th>\n",
       "      <th>train-mlogloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.039409</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>1.038958</td>\n",
       "      <td>0.000575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.987257</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.986396</td>\n",
       "      <td>0.000696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.943749</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.942460</td>\n",
       "      <td>0.001421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.906008</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.904247</td>\n",
       "      <td>0.001569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.873241</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.871052</td>\n",
       "      <td>0.001416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.844407</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.841728</td>\n",
       "      <td>0.001477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.819448</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.816391</td>\n",
       "      <td>0.001534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.797570</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.794120</td>\n",
       "      <td>0.001630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.778447</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.774565</td>\n",
       "      <td>0.001480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.761174</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.756849</td>\n",
       "      <td>0.001482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.746142</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.741310</td>\n",
       "      <td>0.001531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.732469</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.727168</td>\n",
       "      <td>0.001482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.720330</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.714620</td>\n",
       "      <td>0.001370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.709641</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.703468</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.699814</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.693270</td>\n",
       "      <td>0.001138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.691297</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.684293</td>\n",
       "      <td>0.000951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.683416</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.676002</td>\n",
       "      <td>0.000946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.676424</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.668651</td>\n",
       "      <td>0.000703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.670032</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.661847</td>\n",
       "      <td>0.000804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.664168</td>\n",
       "      <td>0.002380</td>\n",
       "      <td>0.655595</td>\n",
       "      <td>0.000825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.659163</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.650143</td>\n",
       "      <td>0.000801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.654441</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>0.645016</td>\n",
       "      <td>0.000932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.650301</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.640508</td>\n",
       "      <td>0.001334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.646246</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.636063</td>\n",
       "      <td>0.001289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.642616</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.632040</td>\n",
       "      <td>0.001329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.639458</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.628472</td>\n",
       "      <td>0.001753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.636328</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.624992</td>\n",
       "      <td>0.001871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.633399</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.621643</td>\n",
       "      <td>0.001707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.630684</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.618441</td>\n",
       "      <td>0.001655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.628165</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.615431</td>\n",
       "      <td>0.001607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>0.550744</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.392570</td>\n",
       "      <td>0.001532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0.550745</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>0.392564</td>\n",
       "      <td>0.001534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>0.550749</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.392503</td>\n",
       "      <td>0.001542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0.550747</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.392471</td>\n",
       "      <td>0.001576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>0.550763</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.392396</td>\n",
       "      <td>0.001568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.550748</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.392334</td>\n",
       "      <td>0.001486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.550762</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>0.392273</td>\n",
       "      <td>0.001505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.550766</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>0.392173</td>\n",
       "      <td>0.001508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.550762</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.392107</td>\n",
       "      <td>0.001463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.550768</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.392051</td>\n",
       "      <td>0.001490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>0.550758</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.391935</td>\n",
       "      <td>0.001465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>0.550758</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.391904</td>\n",
       "      <td>0.001432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>0.550731</td>\n",
       "      <td>0.002251</td>\n",
       "      <td>0.391775</td>\n",
       "      <td>0.001501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>0.550715</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.391661</td>\n",
       "      <td>0.001448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0.550722</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>0.391611</td>\n",
       "      <td>0.001420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.550712</td>\n",
       "      <td>0.002238</td>\n",
       "      <td>0.391587</td>\n",
       "      <td>0.001445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.550707</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.391512</td>\n",
       "      <td>0.001389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.550709</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.001401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.550695</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.391356</td>\n",
       "      <td>0.001491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.550677</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.391296</td>\n",
       "      <td>0.001469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>0.550675</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.391261</td>\n",
       "      <td>0.001493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0.550680</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.391201</td>\n",
       "      <td>0.001476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>0.550702</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.391095</td>\n",
       "      <td>0.001449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.550711</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.390994</td>\n",
       "      <td>0.001383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.550721</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>0.390932</td>\n",
       "      <td>0.001363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.550722</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.390898</td>\n",
       "      <td>0.001395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.550732</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.390782</td>\n",
       "      <td>0.001395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.550729</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>0.390713</td>\n",
       "      <td>0.001354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.550745</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>0.390688</td>\n",
       "      <td>0.001338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.550725</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.390580</td>\n",
       "      <td>0.001287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test-mlogloss-mean  test-mlogloss-std  train-mlogloss-mean  \\\n",
       "0              1.039409           0.000225             1.038958   \n",
       "1              0.987257           0.000395             0.986396   \n",
       "2              0.943749           0.000450             0.942460   \n",
       "3              0.906008           0.000079             0.904247   \n",
       "4              0.873241           0.000440             0.871052   \n",
       "5              0.844407           0.000533             0.841728   \n",
       "6              0.819448           0.000725             0.816391   \n",
       "7              0.797570           0.000814             0.794120   \n",
       "8              0.778447           0.001111             0.774565   \n",
       "9              0.761174           0.001181             0.756849   \n",
       "10             0.746142           0.001203             0.741310   \n",
       "11             0.732469           0.001402             0.727168   \n",
       "12             0.720330           0.001516             0.714620   \n",
       "13             0.709641           0.001888             0.703468   \n",
       "14             0.699814           0.001792             0.693270   \n",
       "15             0.691297           0.002054             0.684293   \n",
       "16             0.683416           0.002126             0.676002   \n",
       "17             0.676424           0.002301             0.668651   \n",
       "18             0.670032           0.002321             0.661847   \n",
       "19             0.664168           0.002380             0.655595   \n",
       "20             0.659163           0.002508             0.650143   \n",
       "21             0.654441           0.002434             0.645016   \n",
       "22             0.650301           0.002221             0.640508   \n",
       "23             0.646246           0.002306             0.636063   \n",
       "24             0.642616           0.002243             0.632040   \n",
       "25             0.639458           0.001851             0.628472   \n",
       "26             0.636328           0.001673             0.624992   \n",
       "27             0.633399           0.001777             0.621643   \n",
       "28             0.630684           0.001867             0.618441   \n",
       "29             0.628165           0.001996             0.615431   \n",
       "..                  ...                ...                  ...   \n",
       "970            0.550744           0.002348             0.392570   \n",
       "971            0.550745           0.002351             0.392564   \n",
       "972            0.550749           0.002350             0.392503   \n",
       "973            0.550747           0.002350             0.392471   \n",
       "974            0.550763           0.002332             0.392396   \n",
       "975            0.550748           0.002326             0.392334   \n",
       "976            0.550762           0.002318             0.392273   \n",
       "977            0.550766           0.002331             0.392173   \n",
       "978            0.550762           0.002326             0.392107   \n",
       "979            0.550768           0.002316             0.392051   \n",
       "980            0.550758           0.002299             0.391935   \n",
       "981            0.550758           0.002292             0.391904   \n",
       "982            0.550731           0.002251             0.391775   \n",
       "983            0.550715           0.002258             0.391661   \n",
       "984            0.550722           0.002249             0.391611   \n",
       "985            0.550712           0.002238             0.391587   \n",
       "986            0.550707           0.002233             0.391512   \n",
       "987            0.550709           0.002242             0.391498   \n",
       "988            0.550695           0.002206             0.391356   \n",
       "989            0.550677           0.002205             0.391296   \n",
       "990            0.550675           0.002212             0.391261   \n",
       "991            0.550680           0.002195             0.391201   \n",
       "992            0.550702           0.002200             0.391095   \n",
       "993            0.550711           0.002179             0.390994   \n",
       "994            0.550721           0.002184             0.390932   \n",
       "995            0.550722           0.002193             0.390898   \n",
       "996            0.550732           0.002182             0.390782   \n",
       "997            0.550729           0.002181             0.390713   \n",
       "998            0.550745           0.002177             0.390688   \n",
       "999            0.550725           0.002182             0.390580   \n",
       "\n",
       "     train-mlogloss-std  \n",
       "0              0.000575  \n",
       "1              0.000696  \n",
       "2              0.001421  \n",
       "3              0.001569  \n",
       "4              0.001416  \n",
       "5              0.001477  \n",
       "6              0.001534  \n",
       "7              0.001630  \n",
       "8              0.001480  \n",
       "9              0.001482  \n",
       "10             0.001531  \n",
       "11             0.001482  \n",
       "12             0.001370  \n",
       "13             0.001076  \n",
       "14             0.001138  \n",
       "15             0.000951  \n",
       "16             0.000946  \n",
       "17             0.000703  \n",
       "18             0.000804  \n",
       "19             0.000825  \n",
       "20             0.000801  \n",
       "21             0.000932  \n",
       "22             0.001334  \n",
       "23             0.001289  \n",
       "24             0.001329  \n",
       "25             0.001753  \n",
       "26             0.001871  \n",
       "27             0.001707  \n",
       "28             0.001655  \n",
       "29             0.001607  \n",
       "..                  ...  \n",
       "970            0.001532  \n",
       "971            0.001534  \n",
       "972            0.001542  \n",
       "973            0.001576  \n",
       "974            0.001568  \n",
       "975            0.001486  \n",
       "976            0.001505  \n",
       "977            0.001508  \n",
       "978            0.001463  \n",
       "979            0.001490  \n",
       "980            0.001465  \n",
       "981            0.001432  \n",
       "982            0.001501  \n",
       "983            0.001448  \n",
       "984            0.001420  \n",
       "985            0.001445  \n",
       "986            0.001389  \n",
       "987            0.001401  \n",
       "988            0.001491  \n",
       "989            0.001469  \n",
       "990            0.001493  \n",
       "991            0.001476  \n",
       "992            0.001449  \n",
       "993            0.001383  \n",
       "994            0.001363  \n",
       "995            0.001395  \n",
       "996            0.001395  \n",
       "997            0.001354  \n",
       "998            0.001338  \n",
       "999            0.001287  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_history = cvXGB(train_X, train_y, test_X, num_rounds=1000)\n",
    "eval_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
