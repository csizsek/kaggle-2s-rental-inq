{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import seaborn as sns\n",
    "import statsmodels as sm\n",
    "from pylab import rcParams\n",
    "from pylab import *\n",
    "from matplotlib.dates import date2num , DateFormatter\n",
    "from PIL import Image\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(font_scale=1.0)\n",
    "rcParams['figure.figsize'] = 8, 6\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette(sns.color_palette('muted'))\n",
    "\n",
    "pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = pd.concat([pd.read_csv('tmp/train_ids.csv', index_col='id'),\n",
    "               pd.read_csv('tmp/test_ids.csv', index_col='id')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_bathrooms.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_bedrooms.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_building_id.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_created.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_description.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_display_address.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_features.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_latlon.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_manager_id.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_photos.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_price.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_street_address.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_others.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low       34284\n",
       "medium    11229\n",
       "high       3839\n",
       "Name: interest_level, dtype: int64"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.interest_level.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del d['num_apts_in_building_q10']\n",
    "del d['num_apts_in_building']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124011 entries, 0 to 124010\n",
      "Columns: 109 entries, listing_id to hours_since_managers_last_listing\n",
      "dtypes: float64(53), int64(44), object(12)\n",
      "memory usage: 104.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# d = pd.concat([d, tf_idfs], axis=1)\n",
    "d.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49352\n"
     ]
    }
   ],
   "source": [
    "tr = d[d.interest_level.notnull()].copy()\n",
    "print len(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trl = tr.interest_level.copy()\n",
    "trf = tr\n",
    "del trf['interest_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74659\n"
     ]
    }
   ],
   "source": [
    "te = d[d.interest_level.isnull()].copy()\n",
    "print len(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tef = te\n",
    "del tef['interest_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tfidf_features = CountVectorizer(stop_words='english', max_features=400)\n",
    "tr_sparse_features = tfidf_features.fit_transform(trf[\"features\"])\n",
    "te_sparse_features = tfidf_features.transform(tef[\"features\"])\n",
    "\n",
    "tfidf_desc = CountVectorizer(stop_words='english', max_features=400)\n",
    "tr_sparse_desc = tfidf_desc.fit_transform(trf[\"desc_clean\"].fillna(\"\"))\n",
    "te_sparse_desc = tfidf_desc.transform(tef[\"desc_clean\"].fillna(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in trf.columns:\n",
    "    if trf.dtypes[c] not in ('int64', 'float64'):\n",
    "        del trf[c]           \n",
    "            \n",
    "for c in tef.columns:\n",
    "    if tef.dtypes[c] not in ('int64', 'float64'):\n",
    "        del tef[c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=1000):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 4\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.8\n",
    "    param['colsample_bytree'] = 0.8\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = sparse.hstack([trf,tr_sparse_features, tr_sparse_desc]).tocsr()\n",
    "test_X = sparse.hstack([tef,te_sparse_features, te_sparse_desc]).tocsr()\n",
    "\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "train_y = np.array(trl.apply(lambda x: target_num_map[x]))\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds, model = runXGB(train_X, train_y, test_X, num_rounds=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "print len(trf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#xgb.plot_importance(model)\n",
    "feature_importance_score = model.get_fscore()\n",
    "feature_importance = pd.Series(feature_importance_score).sort_values().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_features_imp = {}\n",
    "for i, f in enumerate(trf.columns):\n",
    "    f_id = 'f{}'.format(i)\n",
    "    our_features_imp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = pd.read_csv('input/sample_submission.csv').listing_id.values\n",
    "out_df.to_csv(\"output/xgb_starter_with_other_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cvXGB(train_X, train_y, test_X, seed_val=0, num_rounds=1000, nfold=3):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 4\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.8\n",
    "    param['colsample_bytree'] = 0.8\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    eval_hist = xgb.cv(plst, xgtrain, num_rounds, nfold=nfold)\n",
    "\n",
    "    \n",
    "    return eval_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-mlogloss-mean</th>\n",
       "      <th>test-mlogloss-std</th>\n",
       "      <th>train-mlogloss-mean</th>\n",
       "      <th>train-mlogloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.030193</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>1.029532</td>\n",
       "      <td>0.000742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.974447</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.973316</td>\n",
       "      <td>0.001046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.924540</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.922869</td>\n",
       "      <td>0.000825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.882113</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.879926</td>\n",
       "      <td>0.000503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.845211</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.842468</td>\n",
       "      <td>0.000359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.814060</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.810897</td>\n",
       "      <td>0.000826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.787687</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.784104</td>\n",
       "      <td>0.000726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.762934</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.758865</td>\n",
       "      <td>0.000846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.741165</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.736627</td>\n",
       "      <td>0.001018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.721896</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.716915</td>\n",
       "      <td>0.000662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.705096</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.699708</td>\n",
       "      <td>0.000482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.689750</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.683963</td>\n",
       "      <td>0.000374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.676474</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>0.670186</td>\n",
       "      <td>0.000310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.664354</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.657645</td>\n",
       "      <td>0.000489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.653564</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.646410</td>\n",
       "      <td>0.000229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.643767</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.636266</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.635116</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.627217</td>\n",
       "      <td>0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.627091</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.618788</td>\n",
       "      <td>0.000258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.619943</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.611236</td>\n",
       "      <td>0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.613447</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.604422</td>\n",
       "      <td>0.000357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.607429</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.598055</td>\n",
       "      <td>0.000460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.602164</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.592390</td>\n",
       "      <td>0.000421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.597339</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.587192</td>\n",
       "      <td>0.000437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.592897</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.582388</td>\n",
       "      <td>0.000462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.588778</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.577918</td>\n",
       "      <td>0.000510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.585201</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.573987</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.581941</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.570332</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.578910</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.566942</td>\n",
       "      <td>0.000558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.576022</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.563709</td>\n",
       "      <td>0.000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.573385</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.560730</td>\n",
       "      <td>0.000515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>0.514597</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.311634</td>\n",
       "      <td>0.022374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0.514601</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.311531</td>\n",
       "      <td>0.022390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>0.514598</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.311395</td>\n",
       "      <td>0.022360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0.514612</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.311293</td>\n",
       "      <td>0.022393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>0.514636</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.311217</td>\n",
       "      <td>0.022404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.514659</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.311093</td>\n",
       "      <td>0.022376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.514658</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>0.310989</td>\n",
       "      <td>0.022427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.514693</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.310903</td>\n",
       "      <td>0.022445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.514697</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.310855</td>\n",
       "      <td>0.022433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.514721</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>0.310744</td>\n",
       "      <td>0.022467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>0.514704</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.310615</td>\n",
       "      <td>0.022508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>0.514707</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.310459</td>\n",
       "      <td>0.022553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>0.514731</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.310380</td>\n",
       "      <td>0.022583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>0.514741</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.310277</td>\n",
       "      <td>0.022608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0.514753</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.310142</td>\n",
       "      <td>0.022697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.514764</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.310092</td>\n",
       "      <td>0.022698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.514797</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>0.309962</td>\n",
       "      <td>0.022666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.514809</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.309828</td>\n",
       "      <td>0.022682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.514849</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.309693</td>\n",
       "      <td>0.022747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.514875</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.309627</td>\n",
       "      <td>0.022722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>0.514890</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.309564</td>\n",
       "      <td>0.022699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0.514888</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.309491</td>\n",
       "      <td>0.022651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>0.514916</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.309401</td>\n",
       "      <td>0.022626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.514924</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.309341</td>\n",
       "      <td>0.022633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.514934</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.309250</td>\n",
       "      <td>0.022696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.514948</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>0.309173</td>\n",
       "      <td>0.022715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.514963</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.309132</td>\n",
       "      <td>0.022746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.514983</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.308960</td>\n",
       "      <td>0.022737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.514975</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.308903</td>\n",
       "      <td>0.022756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.514975</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>0.308809</td>\n",
       "      <td>0.022804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test-mlogloss-mean  test-mlogloss-std  train-mlogloss-mean  \\\n",
       "0              1.030193           0.000925             1.029532   \n",
       "1              0.974447           0.001443             0.973316   \n",
       "2              0.924540           0.001238             0.922869   \n",
       "3              0.882113           0.001055             0.879926   \n",
       "4              0.845211           0.000975             0.842468   \n",
       "5              0.814060           0.000081             0.810897   \n",
       "6              0.787687           0.000632             0.784104   \n",
       "7              0.762934           0.000456             0.758865   \n",
       "8              0.741165           0.000244             0.736627   \n",
       "9              0.721896           0.000363             0.716915   \n",
       "10             0.705096           0.000628             0.699708   \n",
       "11             0.689750           0.000721             0.683963   \n",
       "12             0.676474           0.001070             0.670186   \n",
       "13             0.664354           0.001238             0.657645   \n",
       "14             0.653564           0.001161             0.646410   \n",
       "15             0.643767           0.001251             0.636266   \n",
       "16             0.635116           0.000954             0.627217   \n",
       "17             0.627091           0.000949             0.618788   \n",
       "18             0.619943           0.001068             0.611236   \n",
       "19             0.613447           0.001043             0.604422   \n",
       "20             0.607429           0.000872             0.598055   \n",
       "21             0.602164           0.000825             0.592390   \n",
       "22             0.597339           0.000794             0.587192   \n",
       "23             0.592897           0.000792             0.582388   \n",
       "24             0.588778           0.000857             0.577918   \n",
       "25             0.585201           0.000989             0.573987   \n",
       "26             0.581941           0.001003             0.570332   \n",
       "27             0.578910           0.001000             0.566942   \n",
       "28             0.576022           0.001107             0.563709   \n",
       "29             0.573385           0.001031             0.560730   \n",
       "..                  ...                ...                  ...   \n",
       "970            0.514597           0.001720             0.311634   \n",
       "971            0.514601           0.001733             0.311531   \n",
       "972            0.514598           0.001749             0.311395   \n",
       "973            0.514612           0.001747             0.311293   \n",
       "974            0.514636           0.001760             0.311217   \n",
       "975            0.514659           0.001747             0.311093   \n",
       "976            0.514658           0.001710             0.310989   \n",
       "977            0.514693           0.001699             0.310903   \n",
       "978            0.514697           0.001689             0.310855   \n",
       "979            0.514721           0.001722             0.310744   \n",
       "980            0.514704           0.001741             0.310615   \n",
       "981            0.514707           0.001743             0.310459   \n",
       "982            0.514731           0.001744             0.310380   \n",
       "983            0.514741           0.001733             0.310277   \n",
       "984            0.514753           0.001703             0.310142   \n",
       "985            0.514764           0.001685             0.310092   \n",
       "986            0.514797           0.001676             0.309962   \n",
       "987            0.514809           0.001686             0.309828   \n",
       "988            0.514849           0.001695             0.309693   \n",
       "989            0.514875           0.001677             0.309627   \n",
       "990            0.514890           0.001669             0.309564   \n",
       "991            0.514888           0.001652             0.309491   \n",
       "992            0.514916           0.001646             0.309401   \n",
       "993            0.514924           0.001630             0.309341   \n",
       "994            0.514934           0.001624             0.309250   \n",
       "995            0.514948           0.001614             0.309173   \n",
       "996            0.514963           0.001621             0.309132   \n",
       "997            0.514983           0.001646             0.308960   \n",
       "998            0.514975           0.001640             0.308903   \n",
       "999            0.514975           0.001653             0.308809   \n",
       "\n",
       "     train-mlogloss-std  \n",
       "0              0.000742  \n",
       "1              0.001046  \n",
       "2              0.000825  \n",
       "3              0.000503  \n",
       "4              0.000359  \n",
       "5              0.000826  \n",
       "6              0.000726  \n",
       "7              0.000846  \n",
       "8              0.001018  \n",
       "9              0.000662  \n",
       "10             0.000482  \n",
       "11             0.000374  \n",
       "12             0.000310  \n",
       "13             0.000489  \n",
       "14             0.000229  \n",
       "15             0.000260  \n",
       "16             0.000221  \n",
       "17             0.000258  \n",
       "18             0.000367  \n",
       "19             0.000357  \n",
       "20             0.000460  \n",
       "21             0.000421  \n",
       "22             0.000437  \n",
       "23             0.000462  \n",
       "24             0.000510  \n",
       "25             0.000335  \n",
       "26             0.000500  \n",
       "27             0.000558  \n",
       "28             0.000495  \n",
       "29             0.000515  \n",
       "..                  ...  \n",
       "970            0.022374  \n",
       "971            0.022390  \n",
       "972            0.022360  \n",
       "973            0.022393  \n",
       "974            0.022404  \n",
       "975            0.022376  \n",
       "976            0.022427  \n",
       "977            0.022445  \n",
       "978            0.022433  \n",
       "979            0.022467  \n",
       "980            0.022508  \n",
       "981            0.022553  \n",
       "982            0.022583  \n",
       "983            0.022608  \n",
       "984            0.022697  \n",
       "985            0.022698  \n",
       "986            0.022666  \n",
       "987            0.022682  \n",
       "988            0.022747  \n",
       "989            0.022722  \n",
       "990            0.022699  \n",
       "991            0.022651  \n",
       "992            0.022626  \n",
       "993            0.022633  \n",
       "994            0.022696  \n",
       "995            0.022715  \n",
       "996            0.022746  \n",
       "997            0.022737  \n",
       "998            0.022756  \n",
       "999            0.022804  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_history = cvXGB(train_X, train_y, test_X, num_rounds=1000)\n",
    "eval_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvXGB(train_X, train_y, test_X, num_rounds=1000, nfold=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
