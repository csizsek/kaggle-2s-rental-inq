{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import seaborn as sns\n",
    "import statsmodels as sm\n",
    "from pylab import rcParams\n",
    "from pylab import *\n",
    "from matplotlib.dates import date2num , DateFormatter\n",
    "from PIL import Image\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(font_scale=1.0)\n",
    "rcParams['figure.figsize'] = 8, 6\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette(sns.color_palette('muted'))\n",
    "\n",
    "pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = pd.concat([pd.read_csv('tmp/train_ids.csv', index_col='id'),\n",
    "               pd.read_csv('tmp/test_ids.csv', index_col='id')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_bathrooms.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_bedrooms.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_building_id.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_created.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_description.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_display_address.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_features.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_latlon.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_manager_id.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_photos.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_price.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv('tmp/features_street_address.csv', index_col='id')\n",
    "d = pd.merge(d, e, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low       34284\n",
       "medium    11229\n",
       "high       3839\n",
       "Name: interest_level, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.interest_level.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124011 entries, 0 to 124010\n",
      "Columns: 102 entries, listing_id to daddr_saddr_same\n",
      "dtypes: float64(49), int64(42), object(11)\n",
      "memory usage: 97.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# d = pd.concat([d, tf_idfs], axis=1)\n",
    "d.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49352\n"
     ]
    }
   ],
   "source": [
    "tr = d[d.interest_level.notnull()].copy()\n",
    "print len(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trl = tr.interest_level.copy()\n",
    "trf = tr\n",
    "del trf['interest_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74659\n"
     ]
    }
   ],
   "source": [
    "te = d[d.interest_level.isnull()].copy()\n",
    "print len(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tef = te\n",
    "del tef['interest_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical = [\"manager_id\", \"building_id\"]\n",
    "for f in categorical:\n",
    "        if trf[f].dtype=='object':\n",
    "            #print(f)\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(trf[f].values) + list(tef[f].values))\n",
    "            trf[f] = lbl.transform(list(trf[f].values))\n",
    "            tef[f] = lbl.transform(list(tef[f].values))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'listing_id', u'bathrooms', u'num_bathrooms_bucket', u'bedrooms',\n",
       "       u'num_bedrooms_bucket', u'building_id', u'num_apts_in_building',\n",
       "       u'num_apts_in_building_q10', u'created', u'created_utc',\n",
       "       ...\n",
       "       u'price_q10_all', u'price_q100_all', u'price_q10', u'price_q100',\n",
       "       u'street_address', u'saddr_num_words', u'saddr_has_number',\n",
       "       u'saddr_has_ordinal', u'saddr_num_upper_words', u'daddr_saddr_same'],\n",
       "      dtype='object', length=101)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from scipy import sparse\n",
    "tfidf = CountVectorizer(stop_words='english', max_features=400)\n",
    "tr_sparse = tfidf.fit_transform(trf[\"features\"])\n",
    "te_sparse = tfidf.transform(tef[\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in trf.columns:\n",
    "    if trf.dtypes[c] not in ('int64', 'float64'):\n",
    "        del trf[c]           \n",
    "            \n",
    "for c in tef.columns:\n",
    "    if tef.dtypes[c] not in ('int64', 'float64'):\n",
    "        del tef[c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=1000):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 4\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.8\n",
    "    param['colsample_bytree'] = 0.8\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = sparse.hstack([trf,tr_sparse]).tocsr()\n",
    "test_X = sparse.hstack([tef,te_sparse]).tocsr()\n",
    "\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "train_y = np.array(trl.apply(lambda x: target_num_map[x]))\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds, model = runXGB(train_X, train_y, test_X, num_rounds=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = pd.read_csv('input/sample_submission.csv').listing_id.values\n",
    "out_df.to_csv(\"output/xgb_starter_3_own_features_tfidf_manager_building.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cvXGB(train_X, train_y, test_X, seed_val=0, num_rounds=1000):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 4\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.8\n",
    "    param['colsample_bytree'] = 0.8\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    eval_hist = xgb.cv(plst, xgtrain, num_rounds, nfold=3)\n",
    "\n",
    "    \n",
    "    return eval_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-mlogloss-mean</th>\n",
       "      <th>test-mlogloss-std</th>\n",
       "      <th>train-mlogloss-mean</th>\n",
       "      <th>train-mlogloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.037760</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>1.037353</td>\n",
       "      <td>0.000418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.986576</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.985883</td>\n",
       "      <td>0.000778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.942336</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.941165</td>\n",
       "      <td>0.000693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.904473</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.902864</td>\n",
       "      <td>0.000709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.871742</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.869791</td>\n",
       "      <td>0.001129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.843040</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.840671</td>\n",
       "      <td>0.001124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.817794</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.815117</td>\n",
       "      <td>0.001172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.795887</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.792719</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.776449</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.772991</td>\n",
       "      <td>0.001156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.759514</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.755585</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.744263</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.739989</td>\n",
       "      <td>0.001064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.730803</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.726194</td>\n",
       "      <td>0.001297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.718755</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.713785</td>\n",
       "      <td>0.001324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.708012</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>0.702647</td>\n",
       "      <td>0.001373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.698549</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.692744</td>\n",
       "      <td>0.001252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.689850</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.683745</td>\n",
       "      <td>0.001431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.682055</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>0.675588</td>\n",
       "      <td>0.001304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.674841</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.668066</td>\n",
       "      <td>0.001246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.668478</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.661352</td>\n",
       "      <td>0.001264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.662982</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.655461</td>\n",
       "      <td>0.001242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.657927</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.649907</td>\n",
       "      <td>0.001278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.653122</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.644675</td>\n",
       "      <td>0.001312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.649005</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>0.640185</td>\n",
       "      <td>0.001633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.645410</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.636243</td>\n",
       "      <td>0.002124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.641852</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.632334</td>\n",
       "      <td>0.002016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.638512</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.628656</td>\n",
       "      <td>0.001858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.635536</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.625277</td>\n",
       "      <td>0.001885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.632595</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.621909</td>\n",
       "      <td>0.002007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.629864</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.618743</td>\n",
       "      <td>0.001929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.627431</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.615854</td>\n",
       "      <td>0.001832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>0.551290</td>\n",
       "      <td>0.003224</td>\n",
       "      <td>0.425516</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0.551261</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.425391</td>\n",
       "      <td>0.001688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>0.551239</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.425326</td>\n",
       "      <td>0.001686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0.551237</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.425304</td>\n",
       "      <td>0.001658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>0.551240</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>0.001683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.551234</td>\n",
       "      <td>0.003263</td>\n",
       "      <td>0.425204</td>\n",
       "      <td>0.001722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.551221</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.425165</td>\n",
       "      <td>0.001668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.551203</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>0.425119</td>\n",
       "      <td>0.001608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.551207</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>0.425031</td>\n",
       "      <td>0.001595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.551208</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.425002</td>\n",
       "      <td>0.001575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>0.551215</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.424974</td>\n",
       "      <td>0.001581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>0.551211</td>\n",
       "      <td>0.003262</td>\n",
       "      <td>0.424960</td>\n",
       "      <td>0.001597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>0.551189</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.424872</td>\n",
       "      <td>0.001589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>0.551199</td>\n",
       "      <td>0.003227</td>\n",
       "      <td>0.424807</td>\n",
       "      <td>0.001623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0.551195</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.424754</td>\n",
       "      <td>0.001622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.551183</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>0.424648</td>\n",
       "      <td>0.001574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.551189</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.424476</td>\n",
       "      <td>0.001446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.551202</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>0.424429</td>\n",
       "      <td>0.001464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.551207</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.424391</td>\n",
       "      <td>0.001505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.551214</td>\n",
       "      <td>0.003206</td>\n",
       "      <td>0.424366</td>\n",
       "      <td>0.001517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>0.551208</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.424318</td>\n",
       "      <td>0.001555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0.551180</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.424211</td>\n",
       "      <td>0.001519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>0.551175</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.424173</td>\n",
       "      <td>0.001524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.551159</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.424111</td>\n",
       "      <td>0.001504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.551173</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.424032</td>\n",
       "      <td>0.001456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.551170</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>0.424013</td>\n",
       "      <td>0.001432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.551149</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.423954</td>\n",
       "      <td>0.001497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.551122</td>\n",
       "      <td>0.003206</td>\n",
       "      <td>0.423817</td>\n",
       "      <td>0.001436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.551110</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>0.423767</td>\n",
       "      <td>0.001464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.551112</td>\n",
       "      <td>0.003173</td>\n",
       "      <td>0.423698</td>\n",
       "      <td>0.001511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test-mlogloss-mean  test-mlogloss-std  train-mlogloss-mean  \\\n",
       "0              1.037760           0.000793             1.037353   \n",
       "1              0.986576           0.001264             0.985883   \n",
       "2              0.942336           0.001204             0.941165   \n",
       "3              0.904473           0.001217             0.902864   \n",
       "4              0.871742           0.001138             0.869791   \n",
       "5              0.843040           0.001168             0.840671   \n",
       "6              0.817794           0.001225             0.815117   \n",
       "7              0.795887           0.001356             0.792719   \n",
       "8              0.776449           0.001406             0.772991   \n",
       "9              0.759514           0.001495             0.755585   \n",
       "10             0.744263           0.001544             0.739989   \n",
       "11             0.730803           0.001464             0.726194   \n",
       "12             0.718755           0.001496             0.713785   \n",
       "13             0.708012           0.001547             0.702647   \n",
       "14             0.698549           0.001743             0.692744   \n",
       "15             0.689850           0.001728             0.683745   \n",
       "16             0.682055           0.002131             0.675588   \n",
       "17             0.674841           0.002104             0.668066   \n",
       "18             0.668478           0.002080             0.661352   \n",
       "19             0.662982           0.002366             0.655461   \n",
       "20             0.657927           0.002394             0.649907   \n",
       "21             0.653122           0.002453             0.644675   \n",
       "22             0.649005           0.002120             0.640185   \n",
       "23             0.645410           0.001808             0.636243   \n",
       "24             0.641852           0.001898             0.632334   \n",
       "25             0.638512           0.001958             0.628656   \n",
       "26             0.635536           0.002037             0.625277   \n",
       "27             0.632595           0.001942             0.621909   \n",
       "28             0.629864           0.001913             0.618743   \n",
       "29             0.627431           0.002019             0.615854   \n",
       "..                  ...                ...                  ...   \n",
       "970            0.551290           0.003224             0.425516   \n",
       "971            0.551261           0.003242             0.425391   \n",
       "972            0.551239           0.003253             0.425326   \n",
       "973            0.551237           0.003258             0.425304   \n",
       "974            0.551240           0.003257             0.425279   \n",
       "975            0.551234           0.003263             0.425204   \n",
       "976            0.551221           0.003258             0.425165   \n",
       "977            0.551203           0.003251             0.425119   \n",
       "978            0.551207           0.003237             0.425031   \n",
       "979            0.551208           0.003246             0.425002   \n",
       "980            0.551215           0.003258             0.424974   \n",
       "981            0.551211           0.003262             0.424960   \n",
       "982            0.551189           0.003235             0.424872   \n",
       "983            0.551199           0.003227             0.424807   \n",
       "984            0.551195           0.003225             0.424754   \n",
       "985            0.551183           0.003210             0.424648   \n",
       "986            0.551189           0.003201             0.424476   \n",
       "987            0.551202           0.003212             0.424429   \n",
       "988            0.551207           0.003201             0.424391   \n",
       "989            0.551214           0.003206             0.424366   \n",
       "990            0.551208           0.003211             0.424318   \n",
       "991            0.551180           0.003197             0.424211   \n",
       "992            0.551175           0.003195             0.424173   \n",
       "993            0.551159           0.003183             0.424111   \n",
       "994            0.551173           0.003195             0.424032   \n",
       "995            0.551170           0.003196             0.424013   \n",
       "996            0.551149           0.003218             0.423954   \n",
       "997            0.551122           0.003206             0.423817   \n",
       "998            0.551110           0.003181             0.423767   \n",
       "999            0.551112           0.003173             0.423698   \n",
       "\n",
       "     train-mlogloss-std  \n",
       "0              0.000418  \n",
       "1              0.000778  \n",
       "2              0.000693  \n",
       "3              0.000709  \n",
       "4              0.001129  \n",
       "5              0.001124  \n",
       "6              0.001172  \n",
       "7              0.001100  \n",
       "8              0.001156  \n",
       "9              0.001076  \n",
       "10             0.001064  \n",
       "11             0.001297  \n",
       "12             0.001324  \n",
       "13             0.001373  \n",
       "14             0.001252  \n",
       "15             0.001431  \n",
       "16             0.001304  \n",
       "17             0.001246  \n",
       "18             0.001264  \n",
       "19             0.001242  \n",
       "20             0.001278  \n",
       "21             0.001312  \n",
       "22             0.001633  \n",
       "23             0.002124  \n",
       "24             0.002016  \n",
       "25             0.001858  \n",
       "26             0.001885  \n",
       "27             0.002007  \n",
       "28             0.001929  \n",
       "29             0.001832  \n",
       "..                  ...  \n",
       "970            0.001600  \n",
       "971            0.001688  \n",
       "972            0.001686  \n",
       "973            0.001658  \n",
       "974            0.001683  \n",
       "975            0.001722  \n",
       "976            0.001668  \n",
       "977            0.001608  \n",
       "978            0.001595  \n",
       "979            0.001575  \n",
       "980            0.001581  \n",
       "981            0.001597  \n",
       "982            0.001589  \n",
       "983            0.001623  \n",
       "984            0.001622  \n",
       "985            0.001574  \n",
       "986            0.001446  \n",
       "987            0.001464  \n",
       "988            0.001505  \n",
       "989            0.001517  \n",
       "990            0.001555  \n",
       "991            0.001519  \n",
       "992            0.001524  \n",
       "993            0.001504  \n",
       "994            0.001456  \n",
       "995            0.001432  \n",
       "996            0.001497  \n",
       "997            0.001436  \n",
       "998            0.001464  \n",
       "999            0.001511  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_history = cvXGB(train_X, train_y, test_X, num_rounds=1000)\n",
    "eval_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
